{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBvdpWMW7EDF"
      },
      "source": [
        "# 1. Ładowanie danych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Rozpakowywanie danych (po pierwszym uruchomieniu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'data' directory not found. Trying to unzip 'data.zip'...\n",
            "Unzipped 'data.zip' into 'data/'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "DATA_PATH = 'data'\n",
        "ZIP_PATH = 'data.zip'\n",
        "\n",
        "if not os.path.isdir(DATA_PATH):\n",
        "    print(f\"'{DATA_PATH}' directory not found. Trying to unzip '{ZIP_PATH}'...\")\n",
        "    \n",
        "    if os.path.isfile(ZIP_PATH):\n",
        "        with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
        "            zip_ref.extractall('.')\n",
        "        print(f\"Unzipped '{ZIP_PATH}'\")\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"Neither '{DATA_PATH}' folder nor '{ZIP_PATH}' found.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Blo6VzGf7EDH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "def load_data(dataset: str) -> pd.DataFrame:\n",
        "    if dataset not in [f.split('.')[0] for f in os.listdir(DATA_PATH)]:\n",
        "        raise FileNotFoundError(f\"Dataset {dataset} not available.\")\n",
        "\n",
        "    return pd.read_csv(os.path.join(DATA_PATH, f\"{dataset}.csv\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATASET = 'creditcard'\n",
        "\n",
        "df = load_data(DATASET)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW6fPBfA7EDJ"
      },
      "source": [
        "## Data info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9jMpf1SS7EDK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
            "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
            "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
            "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
            "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
            "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
            "\n",
            "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
            "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
            "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
            "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
            "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
            "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
            "\n",
            "        V26       V27       V28  Amount  Class  \n",
            "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
            "1  0.125895 -0.008983  0.014724    2.69      0  \n",
            "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
            "3 -0.221929  0.062723  0.061458  123.50      0  \n",
            "4  0.502292  0.219422  0.215153   69.99      0  \n",
            "\n",
            "[5 rows x 31 columns]\n"
          ]
        }
      ],
      "source": [
        "print(df.head(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uarcLP6QQ-p"
      },
      "source": [
        "## Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pgoPwqXa7EDL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "DROP_COLUMNS = {\n",
        "    \"creditcard\": ['Time']\n",
        "}\n",
        "PREPROCESS_DATA = {\n",
        "    \"creditcard\": lambda df: preprocess_creditcard(df),\n",
        "}\n",
        "SEED = 42\n",
        "TEST_SIZE = 0.2\n",
        "\n",
        "\n",
        "def preprocess_creditcard(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    scaler = StandardScaler()\n",
        "    df['Amount'] = scaler.fit_transform(df[['Amount']])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def preprocess_data(df: pd.DataFrame, dataset_name: str, return_unsplit=False) -> list:\n",
        "    df = df.drop(columns=DROP_COLUMNS[dataset_name])\n",
        "    df = PREPROCESS_DATA[dataset_name](df)\n",
        "\n",
        "    X = df.drop('Class', axis=1)\n",
        "    y = df['Class']\n",
        "\n",
        "    if not return_unsplit:\n",
        "        return train_test_split(\n",
        "            X, y,\n",
        "            test_size=TEST_SIZE,\n",
        "            random_state=SEED,\n",
        "            stratify=y\n",
        "        )\n",
        "    return X, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Eag2b4a5QMF4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training set info:\n",
            "Shape: (227845, 29)\n",
            "Fraud percentage: 0.1729%\n",
            "\n",
            "Test set info:\n",
            "Shape: (56962, 29)\n",
            "Fraud percentage: 0.1720%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils.validation import check_array\n",
        "\n",
        "X_train, X_test, y_train, y_test = preprocess_data(df, DATASET)\n",
        "\n",
        "X_train_np = check_array(X_train)\n",
        "X_test_np = check_array(X_test)\n",
        "y_test_np = y_test.values\n",
        "\n",
        "# Outliers percentage\n",
        "true_contamination = y_train.mean()\n",
        "print(\"\\nTraining set info:\")\n",
        "print(f\"Shape: {X_train.shape}\")\n",
        "print(f\"Fraud percentage: {y_train.mean()*100:.4f}%\")\n",
        "\n",
        "print(\"\\nTest set info:\")\n",
        "print(f\"Shape: {X_test.shape}\")\n",
        "print(f\"Fraud percentage: {y_test.mean()*100:.4f}%\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqU4F63a7EDN"
      },
      "source": [
        "## Anomaly Detectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vodpcy_u7EDO"
      },
      "outputs": [],
      "source": [
        "from abc import ABC, abstractmethod\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class BaseAnomalyDetector(ABC):\n",
        "    def __init__(self, contamination=0.01, n_neighbors=20, metric='euclidean'):\n",
        "        self.contamination = contamination\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.metric = metric\n",
        "\n",
        "    @abstractmethod\n",
        "    def fit(self, X):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def score_samples(self, X):\n",
        "        pass\n",
        "\n",
        "    def predict(self, X):\n",
        "        scores = self.score_samples(check_array(X))\n",
        "        threshold = np.percentile(scores, 100 * (1 - self.contamination))\n",
        "        return np.where(scores >= threshold, 1, 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "I79dTX1b7EDP"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import LocalOutlierFactor, NearestNeighbors\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.utils.validation import check_array\n",
        "\n",
        "\n",
        "class LocalAnomalyDetector(BaseAnomalyDetector):\n",
        "    def fit(self, X):\n",
        "        self.X_train_ = check_array(X)\n",
        "        self.lof_ = LocalOutlierFactor(\n",
        "            n_neighbors=self.n_neighbors,\n",
        "            metric=self.metric,\n",
        "            contamination=self.contamination,\n",
        "            novelty=True\n",
        "        )\n",
        "        self.lof_.fit(self.X_train_)\n",
        "        return self\n",
        "\n",
        "    def score_samples(self, X):\n",
        "        X = check_array(X)\n",
        "        return -self.lof_.score_samples(X)\n",
        "\n",
        "\n",
        "class GlobalAnomalyDetector(BaseAnomalyDetector):\n",
        "    def fit(self, X):\n",
        "        self.X_train_ = check_array(X)\n",
        "        self.nn_ = NearestNeighbors(\n",
        "            n_neighbors=self.n_neighbors,\n",
        "            metric=self.metric\n",
        "        )\n",
        "        self.nn_.fit(self.X_train_)\n",
        "        return self\n",
        "\n",
        "    def score_samples(self, X):\n",
        "        X = check_array(X)\n",
        "        distances, _ = self.nn_.kneighbors(X)\n",
        "        return distances.mean(axis=1)\n",
        "\n",
        "\n",
        "class BaseIsolationForest(BaseAnomalyDetector):\n",
        "    def __init__(self, contamination=0.01, n_estimators=100, max_samples='auto'):\n",
        "        self.contamination = contamination\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_samples = max_samples\n",
        "        self.model = IsolationForest(\n",
        "            contamination=contamination,\n",
        "            n_estimators=n_estimators,\n",
        "            max_samples=max_samples,\n",
        "        )\n",
        "        self.threshold_ = None\n",
        "\n",
        "    def fit(self, X):\n",
        "        X = check_array(X)\n",
        "        self.model.fit(X)\n",
        "        scores = self.score_samples(X)\n",
        "        self.threshold_ = np.percentile(scores, 100 * self.contamination)\n",
        "        return self\n",
        "\n",
        "    def score_samples(self, X):\n",
        "        X = check_array(X)\n",
        "        return -self.model.score_samples(X)\n",
        "\n",
        "    def predict(self, X):\n",
        "        scores = self.score_samples(check_array(X))\n",
        "        return (scores >= self.threshold_).astype(int)\n",
        "\n",
        "class OneClassSVMDetector(BaseAnomalyDetector):\n",
        "    def __init__(self, contamination=0.01, kernel='rbf', nu='auto', gamma='scale'):\n",
        "        self.kernel = kernel\n",
        "        self.gamma = gamma\n",
        "        self.nu = nu\n",
        "        self.contamination = contamination\n",
        "        self.model = None\n",
        "        self.threshold_ = None\n",
        "\n",
        "    def fit(self, X):\n",
        "        X = check_array(X)\n",
        "\n",
        "        nu_val = np.mean(X, axis=0) if self.nu == 'auto' else self.nu\n",
        "        if self.nu == 'auto':\n",
        "            nu_val = self.contamination\n",
        "\n",
        "        self.model = OneClassSVM(kernel=self.kernel, gamma=self.gamma, nu=nu_val)\n",
        "        self.model.fit(X)\n",
        "\n",
        "        scores = self.score_samples(X)\n",
        "        self.threshold_ = np.percentile(scores, 100 * self.contamination)\n",
        "        return self\n",
        "\n",
        "    def score_samples(self, X):\n",
        "        X = check_array(X)\n",
        "        return -self.model.score_samples(X)\n",
        "\n",
        "    def predict(self, X):\n",
        "        scores = self.score_samples(check_array(X))\n",
        "        return (scores >= self.threshold_).astype(int)\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test comparison on fixed values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "aOfASFCEEIWe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    roc_auc_score,\n",
        "    precision_recall_curve,\n",
        "    average_precision_score,\n",
        "    roc_curve\n",
        ")\n",
        "from sklearn.utils.validation import check_array\n",
        "from typing import Dict, Any\n",
        "\n",
        "\n",
        "def compute_threshold(scores: np.ndarray, contamination: float) -> float:\n",
        "    return np.percentile(scores, 100 * (1 - contamination))\n",
        "\n",
        "\n",
        "def get_predictions(scores: np.ndarray, threshold: float) -> np.ndarray:\n",
        "    return (scores >= threshold).astype(int)\n",
        "\n",
        "\n",
        "def recall_at_fixed_fpr(y_true: np.ndarray, scores: np.ndarray, fpr_threshold: float) -> float:\n",
        "    fpr, tpr, _ = roc_curve(y_true, scores)\n",
        "    return tpr[fpr <= fpr_threshold][-1] if any(fpr <= fpr_threshold) else 0\n",
        "\n",
        "\n",
        "def calculate_metrics(\n",
        "    y_true: np.ndarray,\n",
        "    preds: np.ndarray,\n",
        "    scores: np.ndarray\n",
        ") -> Dict[str, float]:\n",
        "    report = classification_report(y_true, preds, output_dict=True, zero_division=0)\n",
        "\n",
        "    metrics = {\n",
        "        'Precision': report['1']['precision'],\n",
        "        'Recall': report['1']['recall'],\n",
        "        'F1': report['1']['f1-score'],\n",
        "        'AUROC': roc_auc_score(y_true, scores),\n",
        "        'AUPRC': average_precision_score(y_true, scores),\n",
        "        'Recall@5%FP': recall_at_fixed_fpr(y_true, scores, 0.05)\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def plot_curves(\n",
        "    y_true: np.ndarray,\n",
        "    scores: np.ndarray,\n",
        "    model_name: str,\n",
        "    auroc: float,\n",
        "    auprc: float\n",
        ") -> None:\n",
        "    precision, recall, _ = precision_recall_curve(y_true, scores)\n",
        "    fpr, tpr, _ = roc_curve(y_true, scores)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(fpr, tpr, label=f\"AUROC = {auroc:.3f}\")\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(f'{model_name} ROC Curve')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(recall, precision, label=f\"AUPRC = {auprc:.3f}\")\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title(f'{model_name} Precision-Recall Curve')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluate_model(\n",
        "    model: Any,\n",
        "    X_test: np.ndarray,\n",
        "    y_test: np.ndarray,\n",
        "    model_name: str\n",
        ") -> Dict[str, float]:\n",
        "    X_test = check_array(X_test)\n",
        "    scores = model.score_samples(X_test)\n",
        "\n",
        "    threshold = compute_threshold(scores, model.contamination)\n",
        "    preds = get_predictions(scores, threshold)\n",
        "\n",
        "    metrics = calculate_metrics(y_test, preds, scores)\n",
        "\n",
        "    plot_curves(y_test, scores, model_name, metrics['AUROC'], metrics['AUPRC'])\n",
        "\n",
        "    metrics['Model'] = model_name\n",
        "    return metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e44bSVci1wR8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Contamination: 0.0017\n"
          ]
        }
      ],
      "source": [
        "def compare_models(X_train, X_test, y_test, contamination):\n",
        "    X_train_normal = X_train[y_train == 0]\n",
        "\n",
        "    models = {\n",
        "        'LOF (local)': LocalAnomalyDetector(\n",
        "            contamination=contamination,\n",
        "            n_neighbors=1000\n",
        "        ).fit(X_train_normal),\n",
        "\n",
        "        'Global Distance': GlobalAnomalyDetector(\n",
        "            contamination=contamination,\n",
        "            n_neighbors=20\n",
        "        ).fit(X_train),\n",
        "\n",
        "        'Base (Isolation Forest)': BaseIsolationForest(\n",
        "            contamination=contamination,\n",
        "        ).fit(X_train),\n",
        "\n",
        "        'One-Class SVM': OneClassSVMDetector(\n",
        "            contamination=contamination,\n",
        "            kernel='rbf',\n",
        "            nu='auto',\n",
        "            gamma='scale'\n",
        "        ).fit(X_train_normal)\n",
        "    }\n",
        "\n",
        "    results = []\n",
        "    for name, model in models.items():\n",
        "        print(f\"\\nScoring {name}...\")\n",
        "        results.append(evaluate_model(model, X_test, y_test, name))\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "\n",
        "print(f\"Contamination: {true_contamination:.4f}\")\n",
        "\n",
        "# Comparison\n",
        "results_df = compare_models(X_train_np, X_test_np, y_test_np, true_contamination)\n",
        "\n",
        "print(\"\\nFinal Comparison:\")\n",
        "display(results_df.round(4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import (\n",
        "    precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, average_precision_score\n",
        ")\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def cross_validate_neighbors(X, y, contamination, neighbor_values, n_splits=5):\n",
        "    results = []\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    for n in neighbor_values:\n",
        "        print(f\"\\nCross-validating for n_neighbors = {n}...\")\n",
        "\n",
        "        metrics_lof = []\n",
        "        metrics_global = []\n",
        "\n",
        "        for train_idx, test_idx in skf.split(X, y):\n",
        "            X_train, X_test = X[train_idx], X[test_idx]\n",
        "            y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "            X_train_normal = X_train[y_train == 0]\n",
        "\n",
        "            lof_model = LocalAnomalyDetector(\n",
        "                contamination=contamination,\n",
        "                n_neighbors=n\n",
        "            ).fit(X_train_normal)\n",
        "\n",
        "            global_model = GlobalAnomalyDetector(\n",
        "                contamination=contamination,\n",
        "                n_neighbors=n\n",
        "            ).fit(X_train)\n",
        "\n",
        "            for model, name, metrics in [\n",
        "                (lof_model, \"LOF\", metrics_lof),\n",
        "                (global_model, \"Global\", metrics_global)\n",
        "            ]:\n",
        "                y_pred = model.predict(X_test)\n",
        "                y_scores = model.score_samples(X_test)\n",
        "\n",
        "                precision = precision_score(y_test, y_pred, zero_division=0)\n",
        "                recall = recall_score(y_test, y_pred, zero_division=0)\n",
        "                f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "                try:\n",
        "                    auroc = roc_auc_score(y_test, y_scores)\n",
        "                except ValueError:\n",
        "                    auroc = np.nan\n",
        "                try:\n",
        "                    auprc = average_precision_score(y_test, y_scores)\n",
        "                except ValueError:\n",
        "                    auprc = np.nan\n",
        "\n",
        "                r5fp = recall_at_fixed_fpr(y_test, y_scores, 0.05)\n",
        "\n",
        "                metrics.append({\n",
        "                    'Precision': precision,\n",
        "                    'Recall': recall,\n",
        "                    'F1': f1,\n",
        "                    'AUROC': auroc,\n",
        "                    'AUPRC': auprc,\n",
        "                    'Recall@5%FP': r5fp\n",
        "                })\n",
        "\n",
        "        def summarize(metrics_list):\n",
        "            df = pd.DataFrame(metrics_list)\n",
        "            return df.mean().to_dict()\n",
        "\n",
        "        lof_summary = summarize(metrics_lof)\n",
        "        global_summary = summarize(metrics_global)\n",
        "\n",
        "        results.append({\n",
        "            'n_neighbors': n,\n",
        "            'Model': 'LOF',\n",
        "            **lof_summary\n",
        "        })\n",
        "        results.append({\n",
        "            'n_neighbors': n,\n",
        "            'Model': 'Global',\n",
        "            **global_summary\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = load_data(DATASET)\n",
        "X, y = preprocess_data(df, DATASET, return_unsplit=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Cross-validating for n_neighbors = 5...\n",
            "\n",
            "Cross-validating for n_neighbors = 10...\n",
            "\n",
            "Cross-validating for n_neighbors = 50...\n",
            "\n",
            "Cross-validating for n_neighbors = 100...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_neighbors</th>\n",
              "      <th>Model</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>AUROC</th>\n",
              "      <th>AUPRC</th>\n",
              "      <th>Recall@5%FP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>LOF</td>\n",
              "      <td>0.0017</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.0035</td>\n",
              "      <td>0.7630</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.3824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>Global</td>\n",
              "      <td>0.0016</td>\n",
              "      <td>0.9025</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.9451</td>\n",
              "      <td>0.0621</td>\n",
              "      <td>0.7987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>LOF</td>\n",
              "      <td>0.0017</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.0035</td>\n",
              "      <td>0.6505</td>\n",
              "      <td>0.0046</td>\n",
              "      <td>0.2276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>Global</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.8882</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.9562</td>\n",
              "      <td>0.0854</td>\n",
              "      <td>0.8618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>50</td>\n",
              "      <td>LOF</td>\n",
              "      <td>0.0017</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.0035</td>\n",
              "      <td>0.9273</td>\n",
              "      <td>0.0288</td>\n",
              "      <td>0.7702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>50</td>\n",
              "      <td>Global</td>\n",
              "      <td>0.0014</td>\n",
              "      <td>0.8294</td>\n",
              "      <td>0.0029</td>\n",
              "      <td>0.9584</td>\n",
              "      <td>0.1300</td>\n",
              "      <td>0.8719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>100</td>\n",
              "      <td>LOF</td>\n",
              "      <td>0.0013</td>\n",
              "      <td>0.7338</td>\n",
              "      <td>0.0025</td>\n",
              "      <td>0.9425</td>\n",
              "      <td>0.1847</td>\n",
              "      <td>0.8435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>100</td>\n",
              "      <td>Global</td>\n",
              "      <td>0.0014</td>\n",
              "      <td>0.7826</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.9591</td>\n",
              "      <td>0.1491</td>\n",
              "      <td>0.8719</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   n_neighbors   Model  Precision  Recall      F1   AUROC   AUPRC  Recall@5%FP\n",
              "0            5     LOF     0.0017  1.0000  0.0035  0.7630  0.0084       0.3824\n",
              "1            5  Global     0.0016  0.9025  0.0031  0.9451  0.0621       0.7987\n",
              "2           10     LOF     0.0017  1.0000  0.0035  0.6505  0.0046       0.2276\n",
              "3           10  Global     0.0015  0.8882  0.0031  0.9562  0.0854       0.8618\n",
              "4           50     LOF     0.0017  1.0000  0.0035  0.9273  0.0288       0.7702\n",
              "5           50  Global     0.0014  0.8294  0.0029  0.9584  0.1300       0.8719\n",
              "6          100     LOF     0.0013  0.7338  0.0025  0.9425  0.1847       0.8435\n",
              "7          100  Global     0.0014  0.7826  0.0027  0.9591  0.1491       0.8719"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "neighbor_vals = [5, 10, 50, 100]\n",
        "\n",
        "cv_df = cross_validate_neighbors(\n",
        "    X=X.to_numpy(),\n",
        "    y=y.to_numpy(),\n",
        "    contamination=true_contamination,\n",
        "    neighbor_values=neighbor_vals,\n",
        "    n_splits=5\n",
        ")\n",
        "\n",
        "display(cv_df.round(4))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
